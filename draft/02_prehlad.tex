\section{Úvod do problematiky}
Saliency a teda detekcia významných oblastí je využívaná v rôznych oblastiach.
Automatizáciou sú modely významných oblastí (anglicky saliency modelov) tažiskom pri segmentácii obrazu alebo detekcii špecifických objektov.
Od saliency modelov sú taktiež závislé aj programi ovládajúce zabezpečovacie zariadenia.
Tým, že zužujú možnosti a proaktívne upozorňujú na podozrivé situácie pomocou zúženia obrazu na zopár oblastí.
Uplatnenie saliency model používa aj oblasť reklamy, kde je vizuálna pozornosť kľúčovým parametrom, čo môže rozhodnúť o úspechu produktu, veď aký význam by mala reklama, kde si nevšimnete prezentovaný produkt alebo si všimnete iba jeho 'menej' dokonalé časti.
\section{Metódy pre statické obrázky}
Algoritmy pre statické obrazy tvoria základ všetkých saliency modelov a tvoria najstaršiu oblasť výskumu.
V tejto časti uvediem prehľad algoritmov pre výpočet saliency modelov od najjednoduchších cez najznámejšie až po najefektívnejšie.
Na záver uvediem porovnanie všetkých metód pomocou všeobecne uznávaných metrík a dát získaných zo zariadení merajúcich pohyb očí používateľa (eyetrackera).
\subsection{Baseline Center}\label{section:caseline-center}
Baseline center je triviálny model,  ktorý sa vypočítava pomocou Gaussovej krivky vzhľadom na pomer strán, čím predpokladá salientné oblasti presne v strede obrazu.
Nezachytáva však žiadne sémantické aspekty videa, ako ani podvedomé informácie vnímanania obrazu, iba rozlíšenie dané optikou skenujúcou scénu.
\subsection{Hrany}
Skupinu algoritmov využívajúcu význačné prechody v obraze inak nazývame hrany.
Metódy tohoto typu sú vyžívané hlavne v prírodných scénach, kde nie je (sémanticky) význačný objekt.
Takéto metódy sa zakladajú priamo na štúdiu fyziologických vlastností ľudského vizuálneho systému.
Následná imitácia procesov odohrávajúcich sa na sietnici viedla ku vzniku saliency modelov generujúcich plausibilné výsledky\cite{edges-1}.
\subsection{Ittiho model}
Najznámejším modelom pre výpočet významných oblastí pre statické farebné obrazy je ittiho model navrhnutý v roku 1998.
Model zakladá na rozložení obrazu na tri základné charakteristiky obrazu a to farbu, intenzitu a orientáciu.

\begin{figure}[H]
 \centering
 \includegraphics[width=7cm]{pics/itti-1-svk.png}
 \caption{Ucelená vizualizácia ittiho modelu\cite{itty-98}}\label{wrap-fig:1}
\end{figure}
\vspace{10mm}

Chrakteristika farby obsahuje 12 máp (šedotónové obrazy), pričom model používa farebný model RGB.
Na začiatku sa vypočíta intenzita podľa vzťahu \begin{math} I = (R+G+B)/3\end{math}.
Pomocou mapy I sa následne normalizujú všetky farebné kanály modelu RGB.
Model extrahuje štyri farebné kanály červený (r), zelený (g), modrý (b), zltý (y) a pomocou Gausvých pyramíd vytvorí tri rôzne mapy každej farebnej zložky separátne.
Červená zložka sa počíta difenčným spôsobom ako \begin{math} R = r - (g + b)/2 \end{math}, zelená ako \begin{math} G = g - (r + b)/2 \end{math}, modrá ako \begin{math}B = b - (r + g)/2\end{math} a žltá ako \begin{math}Y = (r + g)/2 - |r - g|/2 - b\end{math}.
Chrakteristika intenzity obsahuje šesť máp.
Získaná je pomocou orientovaných gáborových filtrov s orientáciou 0\degree, 45\degree, 90\degree, 135\degree.
Dokopy 42 máp charakteristík je následne lineárne skombinovaných do jednej saliency mapy\cite{itty-98}.


\subsection{Spektrálne rezidua}
Metóda využíva princíp, že potláča štatisticky často opakujúce sa časti obrazu a do popredia stavia časti obrazu, ktoré sa štatisticky odlišujú od ostatných.
Na detekciu používa rýchlu fourierovu transformáciu.
Pomocou nej rozdelí obrázok na amplitúdovú časť a fázovú časť.

\begin{figure}[H]
  \centering
  \includegraphics[width=10cm]{pics/spectral-img.png}
  \caption{Príklad rozloženia typovo rôznych obrázkov\cite{spectral-rezidual}}\label{wrap-fig:2}
\end{figure}
\vspace{10mm}

Amplitúdová zložka sa následne vyhladí, čím sa do popredia dostanú iba informácie, ktoré sa vymykajú z priemeru.
Odčítaním od pôvodnej amplitúdovej zložky dostaneme iba časti obrazu, ktoré sú významné \cite{spectral-rezidual}.
\subsection{Sun Model}
Sun model (Saliency Using Natural statistics) sa snaží simulovať potencionálne ciele sledovania ludského vizuálneho systému.
Model aktívne hodnotí tieto ciele odhadom pravdepodobnosti vzhľadom na všetky pozorované charakteristiky.
Charakteristiky sú spracovávané separátne a teda model nepočíta s chrakteristikami navzájom sa ovplyvňujúcimi.
Údaje získané zo všetkćyh charakteristík  následne spracuje štatisticky.
Model zakladá hlavne na Bayesovom pravidle.
Za výsledok hľadania potom udáva asymetrie v týchto štatistických štruktúrach\cite{sun-1}.
\subsection{Rare Model}
Výrazná väčšina modelov pozornosti typu bottom-up funguje ustáleným postupom, kde sa z pôvodného obrazu extrahuje definovaná množina chrakteristík paralelne a tie sa následne kombinujú alebo inak použijú na výpočet výslednej mapy pozonosti.
Rare model narvhuje sekvenčnú architektúru, kde z pôvodného obrázku extrahuje nízko úrovňové príznaky.
Následne na výsledkoch sériovo vykonáva extrakciu ďalších príznakov (v literatúre nazývané mid-level).
Nakoniec ako posledný krok spojí a normalizuje výsledné chrakteristiky do konečnej mapy významných oblastí.
Rare model ako ňízkoúrovnové chrakteristiky používa jas a colorimetrické rozdiely (ako farebný model používa YCbCr) a následne na mapách rozložených žložiek farebného modelu detekuje orientáciu pomocou gáborových filtrov\cite{rare-1}.
Po extrakcii všetkých charakteristík použije iteratívnu metódu pre optimálne kvantovanie založenú na metóde Otsu\cite{otsu}.
Na takto upravenom vstupe sa následne vyhľadávajú vzácne (z angl. rare) oblasti obrazu.
Metóda preskúmala možnosti nesekvenčnej extrakcie príznakov z obrazu čo bol novým prístupom v oblasti modelov pozornosti.

\begin{figure}[H]
  \centering
  \includegraphics[width=6cm]{pics/rare-1-svk.png}
  \caption{Rare model workflow\cite{rare-1}}\label{wrap-fig:3}
\end{figure}

\section{Metódy pre videá}
Video obsahuje rozsiahlejšie možnosti ako obrazová informácia, pribúdajú ďalšie rozmery ako je pohyb objektov na obraze alebo vplyv zvuku na ľudské vnímanie.
Avšak oproti obrazu je potrebné spracovávať väčšie množtvo dát.
Navyše vo väčšine algoritmov využívajúcich saliency modely je potrebné, aby model dával výsledky v reálnom čase hlavne v oblasti zabezpečovacej techniky.
\subsection{Zohľadnenie audio informácie}
Saliency modely využívaju rôznorodé druhy príznakov a to od geneticky zakorenených, ako sú prechody farieb, alebo intenzít, až po sémantické príznaky, ako je detekcia tváre \cite{salient-faces}.
Majoritná väčšina saliency modelov využíva iba obrazovú zložku, ale zvuková stopa býva nevyužívaná alebo úplne zanedbaná.
Použitie zvuku je známym trikom filmovej scény už desatročia.
Režiséri posilňujú kontrolu nad diváckou pozornosťou práve pomocou zvukového doprovodu.
Prvé štúdie sa zaoberali detekciou reči a tváre, kde je spojitosť jednoznačná \cite{sound-1}.
Neskoršie štúdie dokazujú korelácie aj na všeobecnejšej úrovni a pokusy o extrakciu samotnej charakteristiky zo zvukovej stopy\cite{sound-coutrot-1}.
Tieto pokusy viedli aj k zostaveniu modelov zohladňujúc zvukovú stopu ako samostatnú charakteristiku spolu s kombináciou nízkoúrovňových príznakov obrazu \cite{sound-courot-2}.

\begin{figure}[H]
  \centering
  \includegraphics[width=9.5cm]{pics/courot-1.png}
  \caption{Vizualizácia audiovizuálneho modulu\cite{sound-courot-2}}\label{wrap-fig:4}
\end{figure}
\vspace{10mm}

Model extrahuje video na sekvenciu obrazov (framy) a audio stopu v tvare grafu vlnovej dĺžky.
Potom extrahuje tri typy rôznych chrakteristík.
Nízkoúrovňové príznaky založené na biologicky inšpirovaných saliency modeloch rozdelených na dynamickú časť a statickú časť.
Statická časť sa zameriava na najasnejšie a najkontrastnejšie časti obrazu.
Dynamická časť sa zameriava na relatívny pohyb objektov vhľadom na pozadie (eliminácia pohybu kamery).
Tieto 2 časti sa nakoniec spoja
Dalšou chrakteritikou použitou v tomto modeli je detekcia tváre.
Každý objekt klasifikovaný ako tvár je v saliency mape nahradený oválnym objektom, intenzita daných objektov je daná pomocou metódy Speaker Diarization, ktorá detekuje podľa zvukovej stopy objekt ktorý generuje zvuk.
Metóda predpokladá striedavú konverzáciu n objektov oddelenú pauzou.
Následne spojí vyššie spomínané charakteristiky do jednej výslednej mapy.
Ako posledný krok preloží cez celú mapu baseline center model popísaný v časti \ref{section:caseline-center}.

\subsection{Detekcia pohybu}
V tejto časti sa zmeriame na segmentáciu objektov ktoré sa na scéne pohybujú.
Metódy tohoto typu sa snažia vizualizovať 3D prostredia (v našom prípade disponujeme výskou, širkou, časom) na 2D výstup (obrazový výstup).
Takáto informácia dokáže priblížíť výpočtové modely bližšie k realite.
Ľudský vyzuálny systém totiž nepoužíva iba 2d vstup (ako to prebieha vo drvivej vetšine metód na výpočet významných oblastí).
Taktéto obrazy sú v ľudskom vyzuálnom systéme vysoko hodnotené.
Dôvody, prečo takto ľudský vyzuálny systém pridáva prijoritu práve takýmto oblastiam možeme nájsť v antropológií (citacia?).
Vysvetlenie je jednoduché a to snaha zabezpečit bezpečné prostredie okolo seba a všetko pohybujúce sa narušuje pocit bezpečnosti.
V nasledujúcom texte rozoberieme 2 najpožívanejšie algoritmy používané na detekciu oblastí pohybu v obraze a výpočet vektoru posunu.
Výpočet vektoru pohybu je však iba projekcia 3D vstupných dát do 2D obrazu, nemusí vždy reprezentovať iba pohyb.
Prvým z nich bude LUCAS KANADE\cite{lucas-kanade}, a druhým Horn Schunck\cite{horn-schunck}.
Oba tieto algoritmi používajú jeden spoločný predpoklad a to, že jas daného objektu sa časom nemení.
To značí, že objekt sa na scéne može presunúť  ale svoj jas nemôže zmeniť.
Matematicky vyjadrené I(x(t),y(t),t) je obrazová dvojrozmerná funkcia, ktorá sa mení vzhľadom na čas.
Kedže sa jas obrazu nemení môžeme povedať, že platí:
\begin{equation}
  I(x + dx/dt \sigmat ,y + dy/dt \sigmat, t + \sigmat) = I(x,y,t)
\end{equation}
Z čoho je ľahko odvoditeľné, že:
\begin{equation}
  dI/dt = \sigmai/\sigmax dx/dt + \sigmai/\sigmay dy/dt + dI/dt  =  0
\end{equation}

\subsection{Lucas Kanande}
Algoritmus prvotne vznikol ako návrh pre časovú optimalizáciu problému výpočtu vektoru posunu medzi dvomi krivkami.
Povodné intitívne riešenie vyžadovalo \begin{math} O(M^2 * N^2) \end{math} času pre výpočet daného vektoru ak M,N bolo rozlíšenie daného obrazového vzoru.
Vtedy nahvrhovaná optimalizácia vyžadovala zadanie rozsahu hladania, pomocou ktorého sa vypočítali diferencie pre celý obraz a pre ďalšiu iteráciu sa rozsah vypočítal pomocou horolezeckého algoritmu.
Metóda Lucas Kanade využíva priestorový gradient pre výpočet nových hodnôt a zároveň upravuje hodnotu rozsahu pri výpočte kažkého obrazového pixelu v obraze a nie iba po výpočte celého obrazu.
Pomocou takejto úpravu naivného algortimu sa časová zložitosť zlepšila na \begin{math} O(M^2 log N) \end{math}\cite{lucas-kanade}.

\begin{figure}[H]
  \centering
  \includegraphics[width=7cm]{pics/lukas-kanade.jpg}
  \caption{Vizualizácie výsledkov algoritmu Lucas-Kanade vždy po 1 iterácií\cite{lucas-kanade}}
\end{figure}
\vspace{10mm}

\subsection{Horn-Schunck}
Metóda Horn-Schunck bola prvá, kde bola použitá metóda variácie na výpočet optického toku.
Táto globálna metóda priniesla výpočet  konštanty pre obmedzenie plynulosti optického toku.
Algoritmus používa 2 základné parametre: Počet iterácií a vyhladzovaciu konštantu.
Počet iterácií určuje dĺžku (počet cyklov) simulácie, vyhladzovacia konštanta je použitá po každom cykle simulácie kvôli zjemneniu prechodov a výpočet optimálneho optického toku.

\begin{figure}[H]
  \centering
  \includegraphics[width=7cm]{pics/horn-schunck.png}
  \caption{Vizualizácia pracovného postupu metódy Horn-Schunck}
\end{figure}
\vspace{10mm}

\section{Metriky úspešnosti}
Metriky úspešnosti sú algoritmy pre čo najpresnejšie vyjadrenie presnosti modelov v meratelných jednotkách.
Takýto algoritmus dostáva na vstupe čisté dáta z eye trackera.
Tieto je potrebné predspracovať z dôvodu, že každý výrobca poskytuje iné zariadenia na hardwarovej úrovni a výrobcovia neštandardizujú výstup do jednotnej formy.
Následne je potrebné vytvoriť mapy fixácií ktorá sa používa ako jeden zo vstupných parametrov v algoritmoch rátajúcich metriky úspešnosti.
\\
Metriky úspešnosti možno rozdeliť do 3 štandardných skupín podľa druhu hodnôt na ktorý porovnávajú reálne dáta (v literatúre nazívané ground truth) s vygenerovanýmy mapamy význačných oblastí\cite{metrics-1}.
\begin{enumerate}
  \item\textbf{Založené na porovnávaní hodnôt} - NSS, Percentile, Pf
  \item\textbf{Založené na vyhodnocovaní vzdialeností} - AUC-Judd, AUC-Zhao, AUC Borji, AUC-Li
  \item\textbf{Založeneé na distribúcií} - KL-Div, EMD, CC, SRCC
\end{enumerate}

\subsection{NSS}
NSS (Normalized Scanpath Saliency) metrika narvrhnutá v roku 2005 ktorej autormi sú R. J. Peters a L. Itti.
Metrika zakladá na ohodnotení salientných oblastí vzľadom na pozíciu fixácií samostatne a následne hodnotu normalizuje vzhľadom na počet fixácií v celom obraze\cite{metrics-1}.
\\
Pre každú fixáciu používa vzťah
  \begin{equation}
    NSS(p) =  (SM(p)-\SI{}{\micro}_{SM}) / 	\sigma_{SM}
  \end{equation}
Kde SM je mapa význačných oblastí a p je bod danej fixácie pre ktorú sa hodnota vypočítava.

Pričom mapa fixácií SM je normalizovaná tak aby nadobúdala nulovú strednú hodnotu a zároveň jednotkovú štandardnú dochýlku.
Metrika NSS nadhodnocuje ak je na výslednej saliency mape minimálna rozmanitosť hodnôt (malý rozdiel medzi hodnotami fixácií a strednou hodnotou), pretože v takomto prípade nebude model dostatocne odhonotený, ak nájde presné pozície v prípade, že odchýlka je malá, alebo
rozdiel medzi hodnotami fixácie a strednou hodnotou je vysoké.
Finálna hodnota NSS metriky je určená priemerom hodnôt pre všetky fixácie\cite{metrics-1}.

\begin{equation}
  NSS = 1/N * \sum_{p=1}^{N}NSS(p)
\end{equation}

\subsection{AUC-Judd}
Metrika je clasická AUC ktorú navrhol Judd \cite{auc-judd}.
Ako prvé sa pixely označené ako fixácie spočítajú s rovnakým počtom náhodných pixelov vybraných z mapy význačných oblastí a pixely sú nakoniec považované za klasifikátor úspešnosti.
Následuje prahovanie zvolenou hodnotou, pixely ktoré sú menšie ako prahovacia hodnota sú pokladané za pozadie obrazu a pixely ktoré majú hodnotu vyššiu sú pokladané ako fixácie.
Pre ľubovolne zvolenú prahovaciu hodnotu sú niektoré výsledné oblasti manuálne označené ako pozitívne (True Positives), pobobne niektoré oblasti ktoré nie sú označené ako fixácie sú manuálne označené ako falošne pozitívne (False Positive).
Tieto operácie sú zopakované tisíc krát, nakoniec sa vizualizuje pomocou ROC krivky a plocha pod pod krivkou (Area Under the Curve preto AUC) je výsledným klasifikátorom, ktorého ideálna hodnota je 1.
Hodnota náhodného výberu je 0.5.

\subsection{KL-Div}
V literatúre nazívaná aj Kullback-Leiblerova divergencia\cite{kldiv} je bežne používaná aj mimo oblasti počítačového videnia, ako metóda pre odhad celkovej rozdielnosti medzi dvoma distribúciami.
Moho authorov saliency modelov používa túto metriku, ako hodnotu straty informácie tj. kolko informácií sa strati po vypočitaní daného saliency modelu voči mape fixácií.
\\\\
Každý projekt vytvárajúci model významných oblastí si volí vlastné metriky úspešnosti, podľa ktorých sa určuje úspešnosť daného modelu.
Pre meranie úspešnosti modelov je okrem samotných algoritmov pre meranie úspešnosti potrebné zabezpečiť dostatočne rôznorodú skupinu testovacích dát tkz. datasetov.

\section{Refenčné datasety}
Dataset je testovacia množina vstupov, ktorá sa snaží obsiahnuť dostatočne rôznorodé vzorky vhodné pre komplexné testovanie.
Pri zostavovaní datasetov sú dôležité nielen videá ale eyetracker data alebo nejakým spôsobom zverejnené fixácie (získaný napríklad ja ručným označovaním významných oblastí), aby bolo možné výsledky validovať pomocou vyššie uvedených metrík.
Daľšou charakteristikou datasetu je množsto ľudí na ktorých boli dané viedeá nahrávané.
\\ Príklady datasetov:
\begin{itemize}
	\item \textbf{RSD}\cite{rsd}
	\item \textbf{SAVAM}\cite{savam}
	\item \textbf{Coutrot datasets}\cite{courot-dataset}
  \item \textbf{ASCMN}\cite{accv}
\end{itemize}

\subsection{RSD}
Regional Saliency Dataset sa snaží o čo najobšírnejšie testovanie a rôznorodé videá.
Je rozdelený do 4 hlavných kategórií: \\
\begin{itemize}
	\item \textbf{bezpečnostné záznamy} - Štadardné záznamy z bezpečnostných kamier obsahujú statické pozadie a salientné pohybujúce sa objekty.
Pre túto čast datasetu vyžili záznamy z projektu CAVIAR\cite{rsd-caviar}.
	\item \textbf{Grafika} - Použité animované filmy/seriáli ktoré obsahujú 2D aj 3D grafiku.
  \item \textbf{Prirodzené videá s prvkami grafiky} - Prirodzené videá  podobné bezpečnostným ale s prvkami umelo vložených priamo do obrazového kanálu.
  \item \textbf{Prirodzené videá} - Videá bez pridaných grafických prvkov, tak ako boli nasnímané kamerou.
\end{itemize}

Na vyznačenie zaujímavých oblastí nezvolili techniku (eyetracker) ale manuálne vyznačovanie zaujímavých oblastí pomocou používateľov.
Výskumu sa zúčastnilo 17 mužov 6 žien medzi 10-23 rokov, na označení každého z videa sa podielalo 10-23 ludí.

\begin{figure}[H]
 \centering
 \includegraphics[width=7cm]{pics/rsd.png}
 \caption{Ukážka z každej kategórie videa s oznčenými významnými oblastami}
\end{figure}
\vspace{10mm}

\subsection{SAVAM}
SAVAM (Semiautomatic Visual-Attention Modeling) je dataset nahrávaný priamo pomocou eyetrackera pri sledovaní videí v HD rozlíšení pričom každému nahrávanému používateľovy sú pridelené dáta separátne pre kažké oko.
Dokopy obsahuje 13 minút videa, ktoré bolo otestované na 50 používateľoch rôzneho veku.
Dataset je rozdelený na videá z filmov, ukážky z komerčných videí a stereoskopické videá.
SAVAM taktiež poskytuje všetky raw dáta z eyetrackere ako aj vizualizácie daných dát\cite{savam}.

\subsection{ASCMN dataset}
ASCMN nazvaný podľa rozčlenenia do piatich skupín videa: Abnormálne, bezpečnostné, videá s davom, videá s pohybom a videá s chybamy v obraze (z anglckých názvou: Abnormal, Surveillance, Crowd, Moving, Noise).
Spolu obsahuje 24 videjí, každé video bolo namerané na 10 rôznych používateľoch.
K datasetu je taktiež dostupný validačný kód\cite{accv} vypočítavajúci hodnotiace metriky na lubovolnom modeli pozornosti.

\subsection{Coutrot dataset}
Ide dva rôzne datasety, oba sú nazvané podľa jeho authora, Antoine Coutrota.
Prvý dataset\cite{sound-1} obsahuje videá s dynamickou povahou scény.
Je rozčlenený do štyroch vyzuálne rozličných kategórií.
\begin{itemize}
  \item Jeden pohybyjúci sa objekt
  \item Viacej pohybujúcich sa objektov
  \item Prírodné scény
  \item Konverzačné scény
\end{itemize}
Tento dataset obsahuje dokopy 60 videí, ktoré sledovalo vždy 18 rôznych používateľov.
Všetky videá boli zaznamenanávnané v štyroch rôznych zvukových zvukových podmienkach (využívať budeme iba dáta s pôdvodnou zvukovou stopou). \\
Druhý dataset \cite{coutrot-database-2} obsahuje 15 videí.
Všetky videá obsahujú nahraté stretnutie štyroch konverzujúcich ludí so statickou kamerou, dataset nieje členený do žiadnych kategorií.
Dáta oboch datasetou boli nahrávané pomocou eyetrackera EyeLink 1000 pri 1000Hz, pričom používatelia sedeli 57cm od monitoru.
Eyetracker nahrával iba dáta z dominantného oka pre daného používateľa.

\section{Porovnanie štandardných Metód}
Porovnávanie metód je štandardne publikované formou ucelených benchmarkov.
Príkladom takéhoto banchmarku je mit saliency benchmark\cite{mit-saliency-benchmark}, ktorý sa snaží zgrupovať a porovnávať obrazové modeli pozornosti a zverejnovať referencie na dalšie podobné projekty.
Pre účeli validácie bude vypracovaný podobný benchmark určený pre porovnanie rôznych modelov pozornosti na typovo rôznych datasetoch.
